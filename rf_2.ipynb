{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from  sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to encode values in the dataset for easier computations\n",
    "#Input: dataset, list of labels (empty if first time encoding, or previous labelList of encoding another dataset)\n",
    "#Output: List of label:value mappings, encoded dataset\n",
    "def myEncoder(labelList, data):\n",
    "\n",
    "   encodedData = data.copy(deep=True)\n",
    "\n",
    "   for col in range(0, len(encodedData.columns)):\n",
    "      if(len(labelList) < 40):\n",
    "         labelList.append({})\n",
    "      uniqueVal = 0\n",
    "      \n",
    "      for row in range(0, len(encodedData)):\n",
    "         current = encodedData.iloc[row,col]\n",
    "         if(current not in labelList[col].keys()): #If the current value has not yet been mapped, map it\n",
    "               labelList[col].update({current: uniqueVal})\n",
    "               uniqueVal = uniqueVal + 1\n",
    "\n",
    "         encodedData.iloc[row,col] = labelList[col][current] #Encode the data\n",
    "\n",
    "   return labelList, encodedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('cleanedTrainingData.csv')\n",
    "tLabels = pd.read_csv('trainingsetlabels.csv')\n",
    "trueTest = pd.read_csv('cleanedTestData.csv')\n",
    "labels = tLabels[\"status_group\"]\n",
    "training = training.join(labels)\n",
    "training.date_recorded = pd.to_datetime(training.date_recorded).dt.strftime(\"%Y%m%d\")\n",
    "trueTest.date_recorded = pd.to_datetime(trueTest.date_recorded).dt.strftime(\"%Y%m%d\")\n",
    "\n",
    "stringCols = training.select_dtypes(object)\n",
    "testStrings = trueTest.select_dtypes(object)\n",
    "labelList = []\n",
    "labelList, stringCols = myEncoder(labelList, stringCols)\n",
    "labelList, testStrings = myEncoder(labelList, testStrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in testStrings.columns:\n",
    "   training.loc[:,cols] = stringCols.loc[:,cols]\n",
    "   trueTest.loc[:,cols] = testStrings.loc[:,cols]\n",
    "training.loc[:,\"status_group\"] = stringCols.loc[:,\"status_group\"]\n",
    "\n",
    "tLabels = training.loc[:,\"status_group\"]\n",
    "training = training.drop(\"status_group\", axis = 1)\n",
    "\n",
    "trainingData, testData, trainingLabels, testLabels = train_test_split(training, tLabels, test_size=0.2, random_state=42)\n",
    "\n",
    "for col in trainingData:\n",
    "   trainingData.loc[:, col] = trainingData.loc[:,col].astype(\"float\")\n",
    "   testData.loc[:, col] = testData.loc[:,col].astype(\"float\")\n",
    "   trueTest.loc[:, col] = trueTest.loc[:,col].astype(\"float\")\n",
    "trainingLabels = trainingLabels.astype(\"float\")\n",
    "testLabels = testLabels.astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(trainingData)\n",
    "trainingData = scaler.transform(trainingData)\n",
    "testData = scaler.transform(testData)\n",
    "trueTest = scaler.transform(trueTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_features=10, n_estimators=400,\n",
       "                       n_jobs=-1, oob_score=True, random_state=42,\n",
       "                       warm_start=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'random_state':42,'bootstrap':True, 'criterion': 'entropy', 'max_features': 10, 'n_estimators':400, 'n_jobs':-1, 'oob_score':True, 'warm_start':True}\n",
    "clf = RandomForestClassifier(random_state=42, bootstrap=True, criterion='entropy', max_features=10, n_estimators=400, n_jobs=-1, oob_score=True, warm_start=True)\n",
    "clf.fit(trainingData,trainingLabels)\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = clf.predict(trueTest)\n",
    "idcol = pd.read_csv('cleanedTestData.csv')\n",
    "reversesStatus = dict((v,k) for k,v in labelList[28].items())\n",
    "reverseID = dict((v,k) for k,v in labelList[0].items())\n",
    "trueTest[0:,0] = trueTest[0:,0].astype(\"int\")\n",
    "testPredict = testPredict.astype(\"int\")\n",
    "df = pd.DataFrame()\n",
    "ids = []\n",
    "status = []\n",
    "for row in range(0, len(trueTest)):\n",
    "   ids.append(idcol.iloc[row,0])\n",
    "   status.append(reversesStatus[testPredict[row]])\n",
    "df[\"id\"] = ids\n",
    "df[\"status_group\"] = status\n",
    "df.to_csv(\"preds_03221022.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.nunique of 0        50785\n",
       "1        51630\n",
       "2        17168\n",
       "3        45559\n",
       "4        49871\n",
       "         ...  \n",
       "14845    39307\n",
       "14846    18990\n",
       "14847    28749\n",
       "14848    33492\n",
       "14849    68707\n",
       "Name: id, Length: 14850, dtype: int64>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
